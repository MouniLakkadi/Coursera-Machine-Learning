https://github.com/MouniLakkadi/Coursera-Machine-Learning.git

Course Project submission

Problem Background  :
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively.
These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, 
to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but
they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.
They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 
More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

Data 


The training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Goal :

The goal of your project is to predict the manner in which they did the exercise. This is the “classe” variable in the training set. You may use any of the other
variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample 
error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

Project Submission Writeup :

This includes : 

Libraries used 
Importing the data
Partioning the Training and Testing set
Removing the NA values (Cleaning the data so as to have only Non zero values)
Predicing using Machine Learning Alogorithms (Decision Tree and Random Forests)

---
title: "PML Coursera writeup"
author: "Mounika Lakkadi"
date: "Sunday, April 26, 2015"
output: html_document
---

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
summary(cars)
```

You can also embed plots, for example:

```{r, echo=FALSE}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

#Installing the attaching the required packages

library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)

set.seed(12345)

trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

#Reading the training and test data 

training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))

testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))

#Partioning the training set into two training 60% and test with 40%

inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)

Trainingpartition <- training[inTrain, ] 

Testingpartition <- training[-inTrain, ]

dim(Trainingpartition)

dim(Trainingpartition)

## [1] 11776   160
## [1] 7846  160

#Cleaning the data

NonZerovalueData <- nearZeroVar(Trainingpartition, saveMetrics=TRUE)

NonZerovalueData

myTraining <- myTraining[!myNZVvars]

#creating another subset with Nonzero Variables

NZVvariables <- names(Trainingpartition) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")

NZVvariables

Trainingpartition <- Trainingpartition[!NZVvariables]

#To check the total number of new  observations

dim(Trainingpartition)

## [1] 11776   100


#Transformation 2: Killing first column of Dataset - ID Removing first ID variable so that it does not interfer with ML Algorithms:

Trainingpartition <- Trainingpartition[c(-1)]

#Transformation 3: Cleaning Variables with too many NAs. For Variables that have more than a 60% threshold of NA’s I’m going to leave them out:

trainingV3 <- Trainingpartition 

#creating another subset to iterate in loop

for(i in 1:length(Trainingpartition)) { #for every column in the training dataset
        if( sum( is.na(Trainingpartition[, i] ) ) /nrow(Trainingpartition) >= .6 ) { #if n?? NAs > 60% of total observations
        for(j in 1:length(trainingV3)) {
            if( length( grep(names(Trainingpartition[i]), names(trainingV3)[j]) ) ==1)  { #if the columns are the same:
                trainingV3 <- trainingV3[ , -j] #Remove that column
            }   
        } 
    }
}

#To check the new N?? of observations

dim(trainingV3)

#Seting back to our set:

Trainingpartition <- trainingV3

rm(trainingV3)

## [1] 11776    58

#repeat exact same 3 transformations for our Testingpartition and testing data sets.

clean1 <- colnames(Trainingpartition)
clean2 <- colnames(Trainingpartition[, -58]) #already with classe column removed

Testingpartition <- Testingpartition[clean1]

testing <- testing[clean2]

# checking  the no  of new observations

dim(Testingpartition)

## [1] 7846   58

dim(testing)

## [1] 20 57

#testing <- testing[-length(testing)]

# coerce the data into the same type.

for (i in 1:length(testing) ) {
        for(j in 1:length(Trainingpartition)) {
        if( length( grep(names(Trainingpartition[i]), names(testing)[j]) ) ==1)  {
            class(testing[j]) <- class(Trainingpartition[i])
        }      
    }      
}

#Testing the coercion :

testing <- rbind(training[2, -58] , testing)

testing <- testing[-1,]

# Prediction using Machine Learning algorithms- Decision Tree

modFitA1 <- rpart(classe ~ ., data=Trainingpartition, method="class")

modFitA1

fancyRpartPlot(modFitA1)


 # Predicting:

predictionsA1 <- predict(modFitA1, Testingpartition, type = "class")

#(Moment of truth) Using confusion Matrix to test results:

library(e1071)

confusionMatrix(predictionsA1, Testingpartition$classe)

# Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 2152  195   13    2    0
         B   56 1147   90   56    0
         C   24  167 1218  129   49
         D    0    9   24  872   75
         E    0    0   23  227 1318

Overall Statistics
                                          
               Accuracy : 0.8548          
                 95% CI : (0.8468, 0.8626)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.8159          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9642   0.7556   0.8904   0.6781   0.9140
Specificity            0.9626   0.9681   0.9430   0.9835   0.9610
Pos Pred Value         0.9111   0.8503   0.7675   0.8898   0.8406
Neg Pred Value         0.9854   0.9429   0.9760   0.9397   0.9802
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2743   0.1462   0.1552   0.1111   0.1680
Detection Prevalence   0.3010   0.1719   0.2023   0.1249   0.1998
Balanced Accuracy      0.9634   0.8618   0.9167   0.8308   0.9375

# ML algorithms for prediction: Random Forests

modFitB1 <- randomForest(classe ~. , data=Trainingpartition)

#Predicting in-sample error:

predictionsB1 <- predict(modFitB1, Testingpartition, type = "class")

#(Moment of truth) Using confusion Matrix to test results:

confusionMatrix(predictionsB1, Testingpartition$classe)

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 2232    1    0    0    0
         B    0 1517    2    0    0
         C    0    0 1364    3    0
         D    0    0    2 1282    4
         E    0    0    0    1 1438

Overall Statistics
                                          
               Accuracy : 0.9983          
                 95% CI : (0.9972, 0.9991)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9979          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9993   0.9971   0.9969   0.9972
Specificity            0.9998   0.9997   0.9995   0.9991   0.9998
Pos Pred Value         0.9996   0.9987   0.9978   0.9953   0.9993
Neg Pred Value         1.0000   0.9998   0.9994   0.9994   0.9994
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2845   0.1933   0.1738   0.1634   0.1833
Detection Prevalence   0.2846   0.1936   0.1742   0.1642   0.1834
Balanced Accuracy      0.9999   0.9995   0.9983   0.9980   0.999
